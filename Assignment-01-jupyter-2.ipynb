{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838b47f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Programming Assignment 1 : Odyssey Villagomez - Graduate Student\n",
    "#### Machine Learning (CSCI-4930/5930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c2f358f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1b572e5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First load the dataset into pandas dataframe\n",
    "training = pd.read_csv('dataset/training.csv',header=None,delimiter=',')\n",
    "validation = pd.read_csv('dataset/validation.csv',header=None,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "895d5442",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-315</td>\n",
       "      <td>75</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-243</td>\n",
       "      <td>75</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-289</td>\n",
       "      <td>77</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-776</td>\n",
       "      <td>118</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-388</td>\n",
       "      <td>77</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2         3         4         5         6         7  8\n",
       "0 -315  75   0.205128  0.230769  0.307692  0.146667  0.280000  0.240000  0\n",
       "1 -243  75   0.213333  0.186667  0.293333  0.400000  0.253333  0.186667  0\n",
       "2 -289  77   0.192308  0.230769  0.282051  0.220779  0.220779  0.272727  0\n",
       "3 -776  118  0.271186  0.203390  0.271186  0.200000  0.200000  0.291667  1\n",
       "4 -388  77   0.226190  0.238095  0.250000  0.272727  0.272727  0.207792  1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e388cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : A\n",
    "Print total number of samples in the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2642bac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of samples: \", len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393547c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c4654ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : B\n",
    "Print two numbers in the format: [n0, n1], where\n",
    "n0 represents number of class=0 (negative) samples and n1 represents number of class=1 (positive) samples in the validation dataset: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3be41e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40060 , 19940 ]\n"
     ]
    }
   ],
   "source": [
    "#the class, [0,1] is in the last column: index : 8\n",
    "negative_class = validation[validation[8] == 0] #filter the 0 values and assign to variable\n",
    "positive_class = validation[validation[8] == 1] #filter the 0 values and assign to variable\n",
    "\n",
    "print('[',len(negative_class), ',', len(positive_class), ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94086aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df42187e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : C\n",
    "Print standard deviation of the second feature: \"The length of shorter sequence\" of the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "18eacdff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.278652371559346\n"
     ]
    }
   ],
   "source": [
    "print(validation[1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee931c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e75705",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : D\n",
    "Print median (i.e., 50% percentile) of the seventh feature: \"'U' frequencies of sequence 2\" of the validation dataset: \"dataset/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "80b8ebd0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2203389999999999\n"
     ]
    }
   ],
   "source": [
    "print(validation[6].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd32de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1db711",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : E\n",
    "Complete the function \"confusion_matrix\" partially defined that takes two arrays of target variable \"y\": y_actual and y_pred denoting ground truth class labels and predicted class labels for the N samples when N is the length of both the arrays. The function should return a list of 4 metrics: TN, FP, FN, TP (in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "894cfc78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_actual, y_pred):\n",
    "    # the function takes two arrays of target variable \"y\": y_actual and y_pred\n",
    "    #    denoting ground truth class labels and predicted class labels for the N samples\n",
    "    #    when N is the length of both the arrays.\n",
    "    # The function should return a list of 4 metrics: TN, FP, FN, TP (in this order).\n",
    "    assert(len(y_actual)==len(y_pred))\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    #@TODO\n",
    "    #compare actual to predicted \n",
    "    for actual, pred in zip(y_actual, y_pred):\n",
    "        if actual == 1 and pred == 1:\n",
    "                TP = TP +1\n",
    "        if actual == 1 and pred == 0:\n",
    "                FN = FN + 1 \n",
    "        if actual == 0 and pred == 0:\n",
    "                TN = TN + 1 \n",
    "        if actual == 0 and pred == 1:\n",
    "                FP = FP + 1\n",
    "    return [TN,FP, FN, TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8751402e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])) #Expected to print: [1, 0, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ac653",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : F\n",
    "You need to complete the accuracy function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return accuracy. In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bd84ea7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return accuracy\n",
    "\n",
    "    \n",
    "    acc_value = 0\n",
    "    \n",
    "    #@TODO\n",
    "    #accuray = TN + TP / Total\n",
    "    TN = conf_mat[0]\n",
    "    TP = conf_mat[3]\n",
    "\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    correct = TN + TP\n",
    "    total = TN + FP + FN + TP\n",
    "\n",
    "    if total == 0: \n",
    "        return(-1)\n",
    "        #acc_value = -1\n",
    "    else:     \n",
    "        acc_value = correct/total\n",
    "    \n",
    "    return acc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f10b0492",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 0.75\n",
    "print(accuracy(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc674194",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : G\n",
    "You need to complete the precision function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return precision. It is also known as Positive Predictive Value (PPV). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a2eee237",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def precision(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return precision. It is also known as Positive Predictive Value (PPV)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    prec_value = 0\n",
    "    #print(\"TN:\",TN, \"FP:\",FP, \"FN:\",FN, \"TP:\", TP)\n",
    "    \n",
    "    #@TODO\n",
    "    if (TP + FP) == 0:\n",
    "        return(-1)\n",
    "        #prec_value = -1\n",
    "    else:    \n",
    "        prec_value = TP/(TP+FP)\n",
    "\n",
    "    return prec_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5619a55d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 1.0\n",
    "print(precision(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e39126",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : H\n",
    "You need to complete the recall function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return recall. It is also known as Sensitivity, or True Positive Rate (TPR). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0e86b304",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recall(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return recall. It is also known as Sensitivity, or True Positive Rate (TPR)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    rec_value = 0\n",
    "    \n",
    "    #@TODO\n",
    "    if (TP + FN) == 0:\n",
    "        return(-1)\n",
    "        #rec_value = -1\n",
    "    else:    \n",
    "        rec_value = TP/(TP + FN)\n",
    "    \n",
    "    return rec_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e73ff7b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1])  #Expected to print 0.6666666666\n",
    "print(recall(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a918017",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : I\n",
    "You need to complete the F1 function partially defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return F1. It is the harmonic mean of precision and recall. In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8caa8d9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def F1(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return F1 score. It is the harmonic mean of precision and recall\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    f1_value = 0\n",
    "\n",
    "\n",
    "    #@TODO\n",
    "    if (TP + FP) == 0:\n",
    "        return(-1)\n",
    "        #prec_value = -1\n",
    "    else:     \n",
    "        prec_value = TP/(TP+FP)\n",
    "    \n",
    "    if (TP +FN) == 0:\n",
    "        return(-1)\n",
    "        #rec_value = -1\n",
    "    else: \n",
    "        rec_value = TP/(TP + FN)\n",
    "\n",
    "    if (prec_value + rec_value) == 0:\n",
    "        return(-1)\n",
    "        #f1_value = -1\n",
    "    else:\n",
    "        f1_value = 2 * ((prec_value * rec_value)/(prec_value + rec_value))\n",
    "\n",
    "    return f1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc0f0529",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.8\n",
    "print(F1(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9a8df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : J\n",
    "You need to complete the MCC function defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return Matthews Correlation Coefficient (MCC). In case of Division by Zero error, return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d45acf21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def MCC(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return Matthews correlation coefficient (MCC)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    mcc_value = 0\n",
    "    \n",
    "    #@TODO\n",
    "    denominator = math.sqrt( ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) )\n",
    "    if denominator == 0: \n",
    "        return(-1)\n",
    "        #mcc_value = -1\n",
    "    else:     \n",
    "        mcc_value = ((TP * TN) - (FP * FN))/denominator \n",
    "\n",
    "    return mcc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "291f57e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.5773502691896258\n",
    "print(MCC(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b155e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : K\n",
    "You need to complete the FDR function defined in the file that takes a confusion matrix, i.e. the list of the four metrics: [TN, FP, FN, TP], in this order, and return False Discovery Rate (FDR). In case of Division by Zero error, return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1e1ac905",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FDR(conf_mat):\n",
    "    # Given a confusion matrix, i.e. the list of four metrics: [TN,FP, FN, TP], in this order\n",
    "    # return False Discovery Rate (FDR)\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    fdr_value = 0\n",
    "    \n",
    "    #@TODO\n",
    "    if (TP + FP) == 0: \n",
    "        return(-1)\n",
    "        #fdr_value = -1\n",
    "    else:     \n",
    "        fdr_value = FP/(TP+FP)\n",
    "\n",
    "    return fdr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "14553daf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix([1, 0, 1, 1], [0, 0, 1, 1]) #Expected to print 0.0\n",
    "print(FDR(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374f3f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : L\n",
    "Print as a dataframe containing:\n",
    " {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in models/*) after predicting the target variables of the validation data: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9ac1ffab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=1222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:02<00:05,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:27<01:48, 36.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [01:27<00:45, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21,\n",
      "              solver='sgd', tol=1e-09)\n",
      "DecisionTreeClassifier(max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:43<00:00, 17.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.025, kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = validation.iloc[:,:-1]\n",
    "    y_test = validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    #conf_mat = []\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "    acc = 0\n",
    "    acc = accuracy(conf_mat)\n",
    "    \n",
    "    prec = 0\n",
    "    prec = precision(conf_mat)\n",
    "    \n",
    "    rec = 0\n",
    "    rec = recall(conf_mat)\n",
    "    \n",
    "    f1 = 0\n",
    "    f1 = F1(conf_mat)\n",
    "    \n",
    "    mcc = 0\n",
    "    mcc = MCC(conf_mat)\n",
    "    \n",
    "    fdr = 0\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result = result.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result.columns),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7ff4a06b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after predicting the target variables of the validation data\n",
      "           model_name  Accuracy  Precision   Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.337583  0.334082   0.99995  0.500835  0.050929   \n",
      "1  models/Model_2.pkl  0.334083  0.332910   0.99995  0.499518  0.028982   \n",
      "2  models/Model_3.pkl  0.667667 -1.000000   0.00000 -1.000000 -1.000000   \n",
      "3  models/Model_4.pkl  0.390483  0.352497   0.99659  0.520789  0.168805   \n",
      "4  models/Model_5.pkl  0.333583  0.332744   0.99995  0.499330  0.024302   \n",
      "5  models/Model_6.pkl  0.337500  0.334054   0.99995  0.500804  0.050516   \n",
      "\n",
      "        FDR  \n",
      "0  0.665918  \n",
      "1  0.667090  \n",
      "2 -1.000000  \n",
      "3  0.647503  \n",
      "4  0.667256  \n",
      "5  0.665946  \n"
     ]
    }
   ],
   "source": [
    "print('Metrics after predicting the target variables of the validation data')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ea75a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : M\n",
    "Print the model name with path which is performing superior among the 6 pretrained models in terms of accuracy, given the performance result dataframe from “L”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9b3aa6c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.667667          \n",
       "Precision    -1.0               \n",
       "Recall        0.0               \n",
       "F1           -1.0               \n",
       "MCC          -1.0               \n",
       "FDR          -1.0               \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['Accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878bf60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : N\n",
    "Print the model name with path which is performing the worst among the 6 pretrained models in terms of recall, given the performance result dataframe from “L”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "60d0a611",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.667667          \n",
       "Precision    -1.0               \n",
       "Recall        0.0               \n",
       "F1           -1.0               \n",
       "MCC          -1.0               \n",
       "FDR          -1.0               \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['Recall'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ddce7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : O\n",
    "Scale all the features of the validation set using the formula, z = (x-m)/s,\n",
    "    \n",
    "    where m = mean of a feature in the training set: \"dataset/training.csv\"\n",
    "    \n",
    "    s = standard deviation of the feature in the training set: \"dataset/training.csv\"\n",
    "    \n",
    "    #  DO NOT SCALE the target feature.\n",
    "    \n",
    "    # At the end, return a tuple (X, y), with X being a numpy array of shape (N,8) and y is an N dim array and \n",
    "\n",
    "N is the total number of samples in the validation set: \"dataset/validation.csv\".\n",
    "\n",
    "Store the scaled dataset in a variable (preferably a dataframe) named “X_validation_scaled”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "959dd2b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-315</td>\n",
       "      <td>75</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-243</td>\n",
       "      <td>75</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-289</td>\n",
       "      <td>77</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-776</td>\n",
       "      <td>118</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-388</td>\n",
       "      <td>77</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2         3         4         5         6         7  8\n",
       "0 -315  75   0.205128  0.230769  0.307692  0.146667  0.280000  0.240000  0\n",
       "1 -243  75   0.213333  0.186667  0.293333  0.400000  0.253333  0.186667  0\n",
       "2 -289  77   0.192308  0.230769  0.282051  0.220779  0.220779  0.272727  0\n",
       "3 -776  118  0.271186  0.203390  0.271186  0.200000  0.200000  0.291667  1\n",
       "4 -388  77   0.226190  0.238095  0.250000  0.272727  0.272727  0.207792  1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91d9e669",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set scaled values: \n",
      "              0         1         2         3         4         5         6  \\\n",
      "0      0.775328 -1.002997 -0.325953  0.167255  1.069653 -1.676320  1.387452   \n",
      "1      1.155149 -1.002997 -0.163911 -0.761209  0.723327  3.906838  0.758204   \n",
      "2      0.912485 -0.910311 -0.579139  0.167255  0.451215 -0.042980 -0.009957   \n",
      "3     -1.656587  0.989744  0.978644 -0.409145  0.189161 -0.500924 -0.500269   \n",
      "4      0.390230 -0.910311  0.090006  0.321487 -0.321826  1.101893  1.215834   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "59995 -1.292591  1.082430  0.231075 -0.129629  0.080167  0.233696  0.482927   \n",
      "59996  0.305826  0.943401  0.518031  0.347192 -1.404098  0.091722 -0.064040   \n",
      "59997 -2.031134  1.082430  0.231075 -0.305082  0.281151  0.233696 -0.303639   \n",
      "59998  1.376712 -1.002997 -0.427228  0.080897  0.723327 -0.329198 -0.929301   \n",
      "59999 -1.624935  1.082430  0.317418 -2.102599  0.765511 -0.317275 -0.106986   \n",
      "\n",
      "              7  targets  \n",
      "0     -0.658364  0        \n",
      "1     -2.059975  0        \n",
      "2      0.201713  0        \n",
      "3      0.699464  1        \n",
      "4     -1.504802  1        \n",
      "...         ... ..        \n",
      "59995 -0.395560  1        \n",
      "59996 -0.340345  0        \n",
      "59997 -0.176566  1        \n",
      "59998  0.884320  0        \n",
      "59999  0.042454  1        \n",
      "\n",
      "[60000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "X = validation.copy()\n",
    "X.drop(8, axis=1, inplace=True)  \n",
    "\n",
    "means = []\n",
    "std_deviations = []\n",
    "\n",
    "#TRAINING SET: calculate mean and standard deviation of each column, store in two lists\n",
    "for feature in training.columns:\n",
    "    if feature== 8:\n",
    "        break;\n",
    "    mean = training[feature].mean()\n",
    "    s = training[feature].std()\n",
    "    means.append(mean)\n",
    "    std_deviations.append(s)    \n",
    "#VALIDATION SET: scale all features but last (we dropped the target column at beginning)\n",
    "for feature in validation:\n",
    "    #b/c index error(validations set contains 1 more column, the target feature)\n",
    "    if feature == 8:\n",
    "        break; \n",
    "    X[feature] = (validation[feature] - means[feature])/std_deviations[feature]\n",
    "\n",
    "#print(X.shape)\n",
    "\n",
    "targets = validation[8]\n",
    "\n",
    "X_validation_scaled = X\n",
    "X_validation_scaled['targets'] = targets\n",
    "\n",
    "print('Validation set scaled values: ')\n",
    "print(X_validation_scaled)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf34832c",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1342b3ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : P\n",
    "Print as a dataframe containing:\n",
    "  {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) after  predicting the target variables \"y\" (given) for \"X\" (the scaled validation dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "59717da3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=1222)\n",
      "[38993, 1067, 1859, 18081]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:05<00:11,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "[38840, 1220, 1918, 18022]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:05<01:19, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma='auto')\n",
      "[38990, 1070, 1013, 18927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [01:05<00:33, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21,\n",
      "              solver='sgd', tol=1e-09)\n",
      "[39041, 1019, 1015, 18925]\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "[37920, 2140, 3012, 16928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:21<00:00, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.025, kernel='linear')\n",
      "[38818, 1242, 1525, 18415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@TODO\n",
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result_scaled = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = X_validation_scaled.iloc[:,:-1]\n",
    "    y_test = X_validation_scaled.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "    print(conf_mat)\n",
    "    acc = 0\n",
    "    acc = accuracy(conf_mat)\n",
    "    \n",
    "    prec = 0\n",
    "    prec = precision(conf_mat)\n",
    "    \n",
    "    rec = 0\n",
    "    rec = recall(conf_mat)\n",
    "    \n",
    "    f1 = 0\n",
    "    f1 = F1(conf_mat)\n",
    "    \n",
    "    mcc = 0\n",
    "    mcc = MCC(conf_mat)\n",
    "    \n",
    "    fdr = 0\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result_scaled = result_scaled.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result_scaled.columns),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "72cccafb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Models after predicting using scaled values: \n",
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.951233  0.944276   0.906770  0.925143  0.889404   \n",
      "1  models/Model_2.pkl  0.947700  0.936597   0.903811  0.919912  0.881411   \n",
      "2  models/Model_3.pkl  0.965283  0.946492   0.949198  0.947843  0.921828   \n",
      "3  models/Model_4.pkl  0.966100  0.948907   0.949097  0.949002  0.923614   \n",
      "4  models/Model_5.pkl  0.914133  0.887770   0.848947  0.867925  0.804802   \n",
      "5  models/Model_6.pkl  0.953883  0.936816   0.923521  0.930121  0.895760   \n",
      "\n",
      "        FDR  \n",
      "0  0.055724  \n",
      "1  0.063403  \n",
      "2  0.053508  \n",
      "3  0.051093  \n",
      "4  0.112230  \n",
      "5  0.063184  \n"
     ]
    }
   ],
   "source": [
    "print('Metrics of Models after predicting using scaled values: ')\n",
    "print(result_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1855db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : Q\n",
    "Print the model name with path which is performing superior in terms of accuracy, given the performance result dataframe from “P”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4c0ffe9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.965283          \n",
       "Precision     0.946492          \n",
       "Recall        0.949198          \n",
       "F1            0.947843          \n",
       "MCC           0.921828          \n",
       "FDR           0.053508          \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_scaled.loc[result['Accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480f160",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : R\n",
    "Print the model name with path which is performing the worst in terms of recall, given the performance result dataframe from “P”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7cd8c6cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.965283          \n",
       "Precision     0.946492          \n",
       "Recall        0.949198          \n",
       "F1            0.947843          \n",
       "MCC           0.921828          \n",
       "FDR           0.053508          \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_scaled.loc[result['Recall'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d799b0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : S\n",
    "Flip the prediction of Model 1, and then compute and\n",
    " print as a dataframe containing: {acc,prec,rec,f1,mcc,FDR} \n",
    "on the original (i.e., not-scaled) validation dataset: \"dataset/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "32df10bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipped predictions for Model 1\n",
      "         0    1         2         3         4         5         6         7  8\n",
      "0     -315  75   0.205128  0.230769  0.307692  0.146667  0.280000  0.240000  1\n",
      "1     -243  75   0.213333  0.186667  0.293333  0.400000  0.253333  0.186667  1\n",
      "2     -289  77   0.192308  0.230769  0.282051  0.220779  0.220779  0.272727  1\n",
      "3     -776  118  0.271186  0.203390  0.271186  0.200000  0.200000  0.291667  0\n",
      "4     -388  77   0.226190  0.238095  0.250000  0.272727  0.272727  0.207792  0\n",
      "...    ...  ..        ...       ...       ...       ...       ...       ... ..\n",
      "59995 -707  120  0.233333  0.216667  0.266667  0.233333  0.241667  0.250000  0\n",
      "59996 -404  117  0.247863  0.239316  0.205128  0.226891  0.218487  0.252101  1\n",
      "59997 -847  120  0.233333  0.208333  0.275000  0.233333  0.208333  0.258333  0\n",
      "59998 -201  75   0.200000  0.226667  0.293333  0.207792  0.181818  0.298701  1\n",
      "59999 -770  120  0.237705  0.122951  0.295082  0.208333  0.216667  0.266667  0\n",
      "\n",
      "[60000 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=1222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_1_validation = validation.copy()\n",
    "\n",
    "#flip predictions \n",
    "flipped_array = []\n",
    "\n",
    "for item in model_1_validation[8]:\n",
    "    if item == 0:\n",
    "        item = 1\n",
    "        flipped_array.append(item)\n",
    "    else: \n",
    "        item = 0\n",
    "        flipped_array.append(item)\n",
    "\n",
    "model_1_validation[8] = flipped_array\n",
    "print(\"Flipped predictions for Model 1\")\n",
    "print(model_1_validation) \n",
    "\n",
    "#@TODO\n",
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_1 = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\"]\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = model_1_validation.iloc[:,:-1]\n",
    "    y_test = model_1_validation.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    #conf_mat = []\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "    acc = 0\n",
    "    acc = accuracy(conf_mat)\n",
    "    \n",
    "    prec = 0\n",
    "    prec = precision(conf_mat)\n",
    "    \n",
    "    rec = 0\n",
    "    rec = recall(conf_mat)\n",
    "    \n",
    "    f1 = 0\n",
    "    f1 = F1(conf_mat)\n",
    "    \n",
    "    mcc = 0\n",
    "    mcc = MCC(conf_mat)\n",
    "    \n",
    "    fdr = 0\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    model_1 = model_1.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=model_1.columns),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "04c4893d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 metrics after flipping predictions:\n",
      "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
      "0  models/Model_1.pkl  0.662417  0.665918   0.992112  0.796928 -0.050929   \n",
      "\n",
      "        FDR  \n",
      "0  0.334082  \n"
     ]
    }
   ],
   "source": [
    "print('model 1 metrics after flipping predictions:')\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab77cf4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task : T\n",
    "Say, in a confusion matrix, the values of the four metrics are: TP=90, TN=1, FP=4, FN=5. Compute F1_original and MCC_original denoting the F1 and MCC scores.\n",
    "\n",
    "Now, flip the predictions, i.e., positives are now will be predicted as negative, and negatives are going to be predicted as positive. \n",
    "\n",
    "Then, compute F1_flipped and MCC_flipped, denoting corresponding F1 and MCC scores. \n",
    "\n",
    "Print/Return the new {TP, TN, FP, FN, F1_original,MCC_original,F1_flipped, MCC_flipped, COMMENT_string} as a dataframe, where COMMENT_string is a string that will be no longer than 200 characters but is going to be your comment about the F1 and MCC values for the two cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9f1f7413",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_original:  0.7969281052304422 MCC_original: -0.050929488373451064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odyss\\AppData\\Local\\Temp/ipykernel_2052/4039341406.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)  # or 199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "#[TN, FP, FN, TP] = conf_mat\n",
    "conf_matrix = [1, 4, 5, 90]\n",
    "\n",
    "F1_original = F1(conf_mat)\n",
    "MCC_original = MCC(conf_mat)\n",
    "\n",
    "print(\"F1_original: \", F1_original, \"MCC_original:\", MCC_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d75af43a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 1, 4, 5, 0.7969281052304422, -0.050929488373451064, 0.7969281052304422, -0.050929488373451064]\n",
      " The F1 and MCC values for the two cases are the same.\n"
     ]
    }
   ],
   "source": [
    "TP = 90\n",
    "TN = 1 \n",
    "FP = 4 \n",
    "FN = 5 \n",
    "\n",
    "#flip prdeictions\n",
    "TN_flipped = 4 #FP\n",
    "FN_flipped = 90 #TP\n",
    "FP_flipped = 1 #TN\n",
    "TP_flipped = 5 #FN\n",
    "\n",
    "conf_matrix = [90,5,4,1]\n",
    "F1_flipped = F1(conf_mat)\n",
    "MCC_flipped = MCC(conf_mat)\n",
    "\n",
    "\n",
    "df = [TP, TN, FP, FN, F1_original,MCC_original, F1_original,MCC_original]\n",
    "print(df)\n",
    "print( \" The F1 and MCC values for the two cases are the same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41215b29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88cd80ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For Graduate Students only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7569210",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: U\n",
    "This task is a follow up of Task P. There is always cost associated with misclassifications. For instance, if a model predicts a ncRNA (class=1) to be non ncRNA (class=0), further verfication will then follow that includes going through the next generation sequencing of those samples costing USD 20 per sample. On the other hand, cost of predicting a non ncRNA to be ncRNA insignificant as most researchers do not care for ncRNAs. They might put it in a piece of paper as a note costing USD 1 per 5 samples. The same cost applies to correct predictions too.\n",
    "\n",
    "What is the cost of predictions with each of the six models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d7873ffd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cost matrix \n",
    "#cost of FP : $20/sample \n",
    "\n",
    "#cost of FN, TP, TN : $0.20/samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23284aa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "61f9c1b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cost_matrix(conf_mat):\n",
    "    [TN, FP, FN, TP] = conf_mat\n",
    "    #fdr_value = 0\n",
    "    \n",
    "#use Confusion Matrix variables to calcualte cost         \n",
    "    FN_cost = 20\n",
    "    FP_cost = 0.2\n",
    "    TP_cost = 0.2\n",
    "    TN_cost = 0.2\n",
    "    \n",
    "    TP = TP*(0.2)\n",
    "    FN = FN*(20)\n",
    "    FP = FP*(0.2)\n",
    "    TN = TN*(0.2)\n",
    "    total_cost = TP+FP+FN+TN    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e13ef70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=1222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:05<00:10,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:21<01:40, 33.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [01:22<00:42, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21,\n",
      "              solver='sgd', tol=1e-09)\n",
      "DecisionTreeClassifier(max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:37<00:00, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.025, kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@TODO\n",
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result_cost = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR','Cost'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = X_validation_scaled.iloc[:,:-1]\n",
    "    y_test = X_validation_scaled.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "   #@TODO: Complete and revise the following...\n",
    "    #conf_mat = []\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "\n",
    "    cost = 0\n",
    "    cost = cost_matrix(conf_mat)\n",
    "    \n",
    "    acc = 0\n",
    "    acc = accuracy(conf_mat)\n",
    "    \n",
    "    prec = 0\n",
    "    prec = precision(conf_mat)\n",
    "    \n",
    "    rec = 0\n",
    "    rec = recall(conf_mat)\n",
    "    \n",
    "    f1 = 0\n",
    "    f1 = F1(conf_mat)\n",
    "    \n",
    "    mcc = 0\n",
    "    mcc = MCC(conf_mat)\n",
    "    \n",
    "    fdr = 0\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result_cost = result_cost.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr,cost],index=result_cost.columns),ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "261cfc40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics including cost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>FDR</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/Model_1.pkl</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>0.944276</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>48808.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/Model_2.pkl</td>\n",
       "      <td>0.947700</td>\n",
       "      <td>0.936597</td>\n",
       "      <td>0.903811</td>\n",
       "      <td>0.919912</td>\n",
       "      <td>0.881411</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>49976.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/Model_3.pkl</td>\n",
       "      <td>0.965283</td>\n",
       "      <td>0.946492</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.947843</td>\n",
       "      <td>0.921828</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>32057.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/Model_4.pkl</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>0.948907</td>\n",
       "      <td>0.949097</td>\n",
       "      <td>0.949002</td>\n",
       "      <td>0.923614</td>\n",
       "      <td>0.051093</td>\n",
       "      <td>32097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/Model_5.pkl</td>\n",
       "      <td>0.914133</td>\n",
       "      <td>0.887770</td>\n",
       "      <td>0.848947</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.804802</td>\n",
       "      <td>0.112230</td>\n",
       "      <td>71637.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/Model_6.pkl</td>\n",
       "      <td>0.953883</td>\n",
       "      <td>0.936816</td>\n",
       "      <td>0.923521</td>\n",
       "      <td>0.930121</td>\n",
       "      <td>0.895760</td>\n",
       "      <td>0.063184</td>\n",
       "      <td>42195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  Accuracy  Precision    Recall        F1       MCC  \\\n",
       "0  models/Model_1.pkl  0.951233  0.944276   0.906770  0.925143  0.889404   \n",
       "1  models/Model_2.pkl  0.947700  0.936597   0.903811  0.919912  0.881411   \n",
       "2  models/Model_3.pkl  0.965283  0.946492   0.949198  0.947843  0.921828   \n",
       "3  models/Model_4.pkl  0.966100  0.948907   0.949097  0.949002  0.923614   \n",
       "4  models/Model_5.pkl  0.914133  0.887770   0.848947  0.867925  0.804802   \n",
       "5  models/Model_6.pkl  0.953883  0.936816   0.923521  0.930121  0.895760   \n",
       "\n",
       "        FDR     Cost  \n",
       "0  0.055724  48808.2  \n",
       "1  0.063403  49976.4  \n",
       "2  0.053508  32057.4  \n",
       "3  0.051093  32097.0  \n",
       "4  0.112230  71637.6  \n",
       "5  0.063184  42195.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model metrics including cost:')\n",
    "result_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ed5b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: V\n",
    "Please comment on which of the six models is the best on the cost basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce6c30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model_4 has the lowest cost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287446d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: W\n",
    "Please comment on which of the six models is the best overall. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8438b6f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All the models except model_5 have similar Accuracy, Precision, Recall, F1, MCC, FDR, and cost. Model_5 performd worse in all categories. Out of the Models 1 - 4, Model 4 has the least cost, and with the other metrics being comparable, Model_4 performed best based on the lowest cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "416ddabe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#see markdown answer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f8b71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6e567f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: X\n",
    "Again a followup of Tasks O and P: Please scale the given validation dataset with an alternate scaling technique you can think of and repeat Task P with the modified scaled validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "385d778d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Min_Max Validation values: \n",
      "              0         1         2         3         4         5         6  \\\n",
      "0      0.831370  0.121212  0.267297  0.393723  0.806452  0.110821  0.551213   \n",
      "1      0.869914  0.121212  0.289259  0.252641  0.754839  0.788889  0.465905   \n",
      "2      0.845289  0.151515  0.232984  0.393723  0.714286  0.309189  0.361765   \n",
      "3      0.584582  0.772727  0.444107  0.306138  0.675232  0.253572  0.295293   \n",
      "4      0.792291  0.151515  0.323672  0.417159  0.599079  0.448232  0.527946   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "59995  0.621520  0.803030  0.342791  0.348611  0.658989  0.342791  0.428586   \n",
      "59996  0.783726  0.757576  0.381681  0.421065  0.437788  0.325548  0.354433   \n",
      "59997  0.546574  0.803030  0.342791  0.321950  0.688941  0.342791  0.321950   \n",
      "59998  0.892398  0.121212  0.253572  0.380601  0.754839  0.274428  0.237129   \n",
      "59999  0.587794  0.803030  0.354493  0.048813  0.761126  0.275876  0.348611   \n",
      "\n",
      "              7  targets  \n",
      "0      0.563135  0        \n",
      "1      0.371430  0        \n",
      "2      0.680771  0        \n",
      "3      0.748850  1        \n",
      "4      0.447364  1        \n",
      "...         ... ..        \n",
      "59995  0.599079  1        \n",
      "59996  0.606631  0        \n",
      "59997  0.629032  1        \n",
      "59998  0.774134  0        \n",
      "59999  0.658989  1        \n",
      "\n",
      "[60000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scale validation data by Mean-Max Normilization: X(new) = Xi – min(X) / max(x) – min(x)\n",
    "X = validation.copy()\n",
    "X.drop(8, axis=1, inplace=True)  \n",
    "\n",
    "\n",
    "mins = []\n",
    "maxs = []\n",
    "\n",
    "#TRAINING SET: calculate min and max of each column, store in two lists\n",
    "for feature in training.columns:\n",
    "    if feature== 8:\n",
    "        break;\n",
    "    \n",
    "    maxVal = training.loc[training[feature].idxmax()][feature]\n",
    "    maxs.append(maxVal)\n",
    "                          \n",
    "    minVal = training.loc[training[feature].idxmin()][feature]\n",
    "    mins.append(minVal) \n",
    "#print('max: ', maxs)\n",
    "#print('min:', mins)\n",
    "#VALIDATION SET: scale all features but last (we dropped the target column at beginning)\n",
    "for feature in validation:\n",
    "    #b/c index error(validations set contains 1 more column, the target feature)\n",
    "    if feature == 8:\n",
    "        break;\n",
    "        \n",
    "    else: \n",
    "        X[feature] = (validation[feature] - mins[feature])/(maxs[feature] - mins[feature])\n",
    "\n",
    "#print(X.shape)\n",
    "\n",
    "targets = validation[8]\n",
    "\n",
    "min_max_scaled = X\n",
    "min_max_scaled['targets'] = targets\n",
    "\n",
    "print(\"Scaled Min_Max Validation values: \")\n",
    "print(min_max_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "484a13a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=1222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:23<00:47, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:22<01:34, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [01:22<00:39, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21,\n",
      "              solver='sgd', tol=1e-09)\n",
      "DecisionTreeClassifier(max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:38<00:00, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.025, kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@TODO\n",
    "#Print as a dataframe containing:\n",
    "# {model_name,acc,prec,rec,f1,mcc,FDR} for each of the N models (listed in model_files) predicting the target variables\n",
    "#  of the validation data.\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "result_scaled_min_max = pd.DataFrame(columns=['model_name','Accuracy','Precision','Recall','F1','MCC','FDR'])\n",
    "\n",
    "model_files=[\"models/Model_1.pkl\",\"models/Model_2.pkl\",\"models/Model_3.pkl\",\\\n",
    "                            \"models/Model_4.pkl\",\"models/Model_5.pkl\",\"models/Model_6.pkl\"]\n",
    "\n",
    "\n",
    "for file_name in tqdm(model_files):\n",
    "    in_file = open(file_name,'rb')\n",
    "    model = pickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "    #Do the prediction by calling the \"predict\" member function of the model object on the\n",
    "    # validation data with the 8 features\n",
    "    X_test = min_max_scaled.iloc[:,:-1]\n",
    "    y_test = min_max_scaled.iloc[:,-1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #@TODO: Complete and revise the following...\n",
    "    conf_mat = []\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(model)\n",
    "    #print(y_test, 'predicted targets: ', y_pred)\n",
    "    acc = 0\n",
    "    acc = accuracy(conf_mat)\n",
    "    \n",
    "    prec = 0\n",
    "    prec = precision(conf_mat)\n",
    "    \n",
    "    rec = 0\n",
    "    rec = recall(conf_mat)\n",
    "    \n",
    "    f1 = 0\n",
    "    f1 = F1(conf_mat)\n",
    "    \n",
    "    mcc = 0\n",
    "    mcc = MCC(conf_mat)\n",
    "    \n",
    "    fdr = 0\n",
    "    fdr = FDR(conf_mat)\n",
    "    \n",
    "    result_scaled_min_max = result_scaled_min_max.append(pd.Series([file_name,acc,prec,rec,f1,mcc,fdr],index=result_scaled_min_max.columns),ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c0e7b8b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics after scaling based on Min-Max Method\n",
      "           model_name  Accuracy Precision   Recall        F1       MCC  FDR\n",
      "0  models/Model_1.pkl  0.667667  -1        0.00000  -1        -1        -1 \n",
      "1  models/Model_2.pkl  0.667667  -1        0.00000  -1        -1        -1 \n",
      "2  models/Model_3.pkl  0.667667  -1        0.00000  -1        -1        -1 \n",
      "3  models/Model_4.pkl  0.667717  1.0       0.00015  0.000301  0.010023  0.0\n",
      "4  models/Model_5.pkl  0.667667  -1        0.00000  -1        -1        -1 \n",
      "5  models/Model_6.pkl  0.667667  -1        0.00000  -1        -1        -1 \n",
      "metrics are similar because divison of zero is returning the error (-1) value for Precision\n"
     ]
    }
   ],
   "source": [
    "print(\"Model metrics after scaling based on Min-Max Method\")\n",
    "print(result_scaled_min_max)\n",
    "print('metrics are similar because divison of zero is returning the error (-1) value for Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ad5f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: Y\n",
    "Print the model name with path which is performing superior in terms of accuracy, given the performance result dataframe from “X”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "947b3749",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.667667          \n",
       "Precision     -1                \n",
       "Recall        0.0               \n",
       "F1            -1                \n",
       "MCC           -1                \n",
       "FDR           -1                \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_scaled_min_max.loc[result['Accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296aabd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: Z\n",
    "Print the model name with path which is performing the worst in terms of recall, given the performance result dataframe from “X”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b837d0f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name    models/Model_3.pkl\n",
       "Accuracy      0.667667          \n",
       "Precision     -1                \n",
       "Recall        0.0               \n",
       "F1            -1                \n",
       "MCC           -1                \n",
       "FDR           -1                \n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_scaled_min_max.loc[result['Recall'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d513958",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I used the Min-Max equation to scale the values for the validation set. This turned out to be a poor method for scaling the values, because it predicted every sample to be a negative. Which ultimately gave FP & TP values of 0, and avg accuracy accross all models was 67%, which is lower than when we scaled using the Stndardization method above. \n",
    "\n",
    "Overall this method of scaling was not good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0383146",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}